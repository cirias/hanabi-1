\begin{abstract}
  We use reinforcement learning to play Hanabi: a card game in which multiple
  agents with partial information cooperate to achieve a common goal.  We
  present two ways of encoding Hanabi as a Markov decision procedure (MDP): a
  process which is complicated by a lack of complete information. We also
  present three ways to use single-agent reinforcement learning algorithms to
  train Hanabi's multi-agent MDP. Finally, we train policies for three variants
  of Hanabi. On a reduced variant of Hanabi, our best policy achieves a perfect
  score on 9\% of the games it plays and achieves an average score of 77\%.
  \todo{Update numbers after final training is done.}
\end{abstract}
