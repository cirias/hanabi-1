\section{Approach}
\label{approach}

Here, we describe the various components we implemented to play and learn
Hanabi. Section \ref{eval} compares the performance of the different
state representations, reward functions, algorithms, and training
methods.

\subsection{Overview}

\subsubsection{Hanabi Game Engine}

\subsubsection{Using OpenAI}

\subsubsection{Space reps}

1) Original

2) New

\subsubsection{Reward Functions}

\subsection{Algorithms}

\subsubsection{TRPO}

\cite{TRPO}

\subsubsection{VPG (if space)}
\subsubsection{CEM (if space)}
\subsubsection{CMA-ES (if space)}

\subsection{Heuristics}

We implemented hardcoded heuristic-based Hanabi players to see if we could
guide the previously discussed algorithms into learning a particular strategy.
Below we discuss two of these heuristic-based players.

\subsubsection{Heuristic}
\subsubsection{SimpleHeuristic}

The SimpleHeuristic player attempts to mimic the strategy that our best
TRPO-trained-on-itself player learns for mini-hanabi.

